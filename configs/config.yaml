# Fichier de configuration générique (à adapter au projet)
dataset:
  name: "zh-plus/tiny-imagenet"  # HuggingFace Datasets
  root: "./data"                 # cache HF datasets
  split:                    # optionnel : noms/tailles de splits
    train: train
    val: validation
    test: validation
  download: true            # ignoré ici (HF gère le téléchargement)
  cache_in_ram: true       # true => charge toutes les images en RAM (uint8) avant train
  cache_max_items: null     # optionnel: limite (debug), ex: 5000
  num_workers: 2
  shuffle: true

preprocess:
  # transformations de base (ex: resize, normalize)
  resize: null              # Tiny ImageNet est déjà en 64x64
  normalize:                # stats ImageNet (baseline)
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  text_tokenizer:           # pour NLP : nom ou paramètres, sinon null

augment:
  # data augmentation (laisser null si non utilisée)
  random_flip: false
  random_crop: false         # => crop 64 avec padding 4
  color_jitter: false
    #brightness: 0.2
    #contrast: 0.2
    #saturation: 0.2
    #hue: 0.05
  spec_augment:             # pour audio : paramètres ou null

model:
  type: tiny_cnn
  num_classes: 200
  input_shape: [3, 64, 64]
  stage_repeats: [2, 2, 2]   # (N1,N2,N3) dans {1,2,3}
  stage_channels: [64, 128, 256]  # (C1,C2,C3)
  rnn:                      # pour RNN/LSTM/GRU : paramètres ou null
    type: null              # lstm/gru
    hidden_size: null
    num_layers: null
    bidirectional: false

train:
  seed: 42
  device: auto              # "cpu", "cuda", ou "auto"
  batch_size: 128
  epochs: 100
  max_steps: null           # entier ou null
  overfit_small: true      # true pour sur-apprendre sur un petit échantillon
  overfit_small_size: 4096   # taille du sous-échantillon quand overfit_small=true
  val_subset_size: 1000      # optionnel: nombre d'exemples utilisés pour la validation (null = tout)

  optimizer:
    name: adam              # sgd/adam/rmsprop
    lr: 0.002
    weight_decay: 0.0
    momentum: 0.9           # utile si SGD

  scheduler:
    name: none              # none/step/cosine/onecycle
    step_size: 10
    gamma: 0.1
    warmup_steps: 0

metrics:
  classification:           # ex: ["accuracy", "f1"]
    - accuracy
  regression: []            # ex: ["mae", "rmse"]

hparams:                    # espace pour mini grid search
  lr: [0.0005, 0.001, 0.005]
  batch_size: [32, 64]
  weight_decay: [0.0, 0.0005]

  # Optionnel: tuner le modèle (si tu veux)
  # stage_repeats: [[1,1,1], [2,2,2], [3,3,3]]
  # stage_channels: [[48,96,192], [64,128,256]]

paths:
  runs_dir: "./runs"
  artifacts_dir: "./artifacts"